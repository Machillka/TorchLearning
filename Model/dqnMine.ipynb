{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as torchNN\n",
    "import torch.nn.functional as torchF\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "\n",
    "from IPython import display\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('nowState', 'action', 'nextState', 'reward'))\n",
    "class MemoryPool():\n",
    "    def __init__(self, capacity) -> None:\n",
    "        self.memory = deque([], maxlen = capacity)\n",
    "    \n",
    "    def AddMemory(self, *arg):\n",
    "        self.memory.append(Transition(*arg))\n",
    "    \n",
    "    def Sample(self, BATCHSIZE):\n",
    "        return random.sample(self.memory, BATCHSIZE)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add network policy and target\n",
    "class Network(torchNN.Module):\n",
    "    def __init__(self, stateNum, actionNum, hiddenUnits) -> None:\n",
    "        super().__init__()\n",
    "        self.liner = torchNN.Sequential(\n",
    "            torchNN.Linear(stateNum, hiddenUnits),\n",
    "            torchNN.LeakyReLU(),\n",
    "            torchNN.Linear(hiddenUnits, hiddenUnits),\n",
    "            torchNN.LeakyReLU(),\n",
    "            torchNN.Linear(hiddenUnits, actionNum),\n",
    "        )\n",
    "\n",
    "    def forward(self, nowState):\n",
    "        return self.liner(nowState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNModel():\n",
    "    def __init__(\n",
    "        self,\n",
    "        stateNum,\n",
    "        actionNum,\n",
    "        hiddenUnits,\n",
    "        episold,\n",
    "        poolCapacity,\n",
    "        environment,\n",
    "        learningRate,\n",
    "        batchSize,\n",
    "    ):\n",
    "        '''\n",
    "        Param:\n",
    "            stateNum: \n",
    "            actionNum:\n",
    "            hiddenUnits:\n",
    "            episold:\n",
    "            poolCapacity:\n",
    "            environment:\n",
    "            learningRate:\n",
    "        '''\n",
    "\n",
    "        self.policyNetwork = Network(stateNum, actionNum, hiddenUnits)\n",
    "        self.targetNetwork = Network(stateNum, actionNum, hiddenUnits)\n",
    "        self.episold = episold\n",
    "        self.memoryPool = MemoryPool(poolCapacity)\n",
    "        self.environment = environment\n",
    "        self.optimizer = torch.optim.Adam(self.policyNetwork.get_parameter(), lr = learningRate)\n",
    "        self.lossFunc = torchNN.SmoothL1Loss()                      # use L1 lossfunction\n",
    "        self.batchSize = batchSize\n",
    "\n",
    "    def ChooseAction(self, nowState) -> torch.Tensor:\n",
    "        '''\n",
    "        Func:\n",
    "            return the next action agent may take\n",
    "        Param:\n",
    "            nowState:   the state agent is in\n",
    "        Return:\n",
    "            shape:      (1, 1), the first d is used for 'BatchSize'      \n",
    "        '''\n",
    "        if random.random() < self.episold:\n",
    "            return torch.Tensor([[self.environment.action_space.sample()]])\n",
    "        with torch.no_grad():\n",
    "            return self.policyNetwork(nowState).max(1).indices.view(1, 1)   \n",
    "        # TODO: Learn the network's max function and indices function\n",
    "\n",
    "    def OptimizeNetwork(self):\n",
    "        if len(self.memoryPool) < self.batchSize:\n",
    "            return\n",
    "\n",
    "        data = self.memoryPool.Sample(self.batchSize)\n",
    "        data = Transition(*zip(*data))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
